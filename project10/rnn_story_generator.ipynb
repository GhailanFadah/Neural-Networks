{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzfDzv2vMNpJ"
      },
      "source": [
        "**Gordon Doore, Ghailan Fadah**\n",
        "\n",
        "Spring 2024\n",
        "\n",
        "CS 443: Bio-inspired Machine Learning\n",
        "\n",
        "# Project 5: Recurrent Neural Networks\n",
        "\n",
        "In this project, you will build a **recurrent neural network** in TensorFlow and train it on a text corpus representing children's fairy tales and, once trained, the network will generate a novel story following a text prompt that you provide. The neural network will process text data as a **character-level model**.\n",
        "\n",
        "### Reminder: AI Policy\n",
        "\n",
        "To improve the quality of your learning and out of fairness to your hardworking classmates, AI (e.g. ChatGPT, Copilot, etc.) should NOT be used in ANY way on this project and extensions. This includes both written analysis, plotting, and code. I will only grade your work, not an AI's. I will stop grading your project if I notice AI-generated content (in any capacity)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VCSDLTGQMNpL"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "plt.show()\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "plt.rcParams.update({'font.size': 20})\n",
        "\n",
        "np.set_printoptions(suppress=True, precision=5)\n",
        "\n",
        "# Automatically reload external modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWzFVMiRMNpM"
      },
      "source": [
        "## Task 1: Three Little Pigs Dev corpus\n",
        "\n",
        "In order to make this a one week project, you are being the provided with the preprocessed datasets. The original story text files are provided, but for the main project you should use the preprocessed versions (`.npz` and `pkl` files).\n",
        "\n",
        "*Building your own preprocessing pipeline from the fairytale raw .txt file would be a good extension!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPpcAs2CMNpN"
      },
      "source": [
        "### 1a. Load in the dev corpus\n",
        "\n",
        "Run the cell below to load in *The Three Little Pigs* story that will serve as our dev corpus (`pigs_dev_7`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANQB8_DpMjJj",
        "outputId": "eede55e9-c1f3-449f-e781-9632399c33e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mount drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = \"/content/drive/MyDrive/data\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2adqgkNXMNpN",
        "outputId": "875c9b1f-d9b8-4fa5-9015-86d91ceba7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Three Little Pigs dev set shape: (345, 2, 7)\n",
            "Three Little Pigs dev labels shape: (345, 2, 7)\n",
            "Three Little Pigs char2ind map loaded.\n",
            "Three Little Pigs ind2char map loaded.\n"
          ]
        }
      ],
      "source": [
        "pigs_dev = np.load(data_path+'/pigs_dev_7.npz')\n",
        "x_pigs = pigs_dev['x']\n",
        "y_pigs = pigs_dev['y']\n",
        "\n",
        "print(f'Three Little Pigs dev set shape: {x_pigs.shape}')\n",
        "print(f'Three Little Pigs dev labels shape: {y_pigs.shape}')\n",
        "\n",
        "with open(data_path+'/pigs_dev_char2ind_map.pkl', 'rb') as file:\n",
        "    char2ind_map_pigs = pickle.load(file)\n",
        "    print('Three Little Pigs char2ind map loaded.')\n",
        "\n",
        "with open(data_path+'/pigs_dev_ind2char_map.pkl', 'rb') as file:\n",
        "    ind2char_map_pigs = pickle.load(file)\n",
        "    print('Three Little Pigs ind2char map loaded.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvEUrL4oMNpN",
        "outputId": "542a455a-1463-4529-a3c4-d5c68e37d85b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " !\"',-.:;?ABDEFGHILMNOPRSTVWY_abcdefghijklmnoprstuvwxyz\n",
            "vocab length is  56\n"
          ]
        }
      ],
      "source": [
        "#question 1\n",
        "pigs_dev_vocab = ''.join(char2ind_map_pigs.keys())\n",
        "print(pigs_dev_vocab)\n",
        "print(\"vocab length is \",len(pigs_dev_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiKURI6CMNpN",
        "outputId": "710f7516-bfb6-4b88-d678-2af643b1dd30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 7)\n",
            "[[17 14  1 25 26 22 24]\n",
            " [ 1 32 35 35 44  1 31]] [[26 17 14  1 25 26 22]\n",
            " [35  1 32 35 35 44  1]]\n"
          ]
        }
      ],
      "source": [
        "#question 2\n",
        "print(x_pigs[0].shape)\n",
        "#question 3\n",
        "print(y_pigs[0],x_pigs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgADTb-BMNpO",
        "outputId": "ffba4e7e-dec3-4f77-bfe5-5984190a49b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "he huffed and he puffed\n"
          ]
        }
      ],
      "source": [
        "#question 4\n",
        "vals = np.array([38, 35, 1, 38, 50, 36, 36, 35, 34, 1, 31, 44, 34, 1, 38, 35, 1, 46, 50, 36, 36, 35, 34]).astype(int)\n",
        "newString = (pigs_dev_vocab[val] for val in vals)\n",
        "print(''.join(newString))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzotTkN1MNpO"
      },
      "source": [
        "### 1b. Questions\n",
        "\n",
        "**Question 1:** Use the files loaded above to print out the char vocabulary as one string (call it `pigs_dev_vocab`). How many tokens are in the vocabulary?\n",
        "\n",
        "There are 56 tokens in the vocab.\n",
        "\n",
        "**Question 2:**\n",
        "\n",
        "(a) How many sequences are processed in one mini-batch in the dev corpus? 2 sequences\n",
        "\n",
        "(b) What is the sequence length? 7 tokens\n",
        "\n",
        "(c) How many mini-batches are there? 345\n",
        "\n",
        "**Question 3:** What is the relationship between x and y within each mini-batch? y should be the next step of x, so that y[i] is x[i] shifted over by 1 token\n",
        "\n",
        "**Question 4:** Use the files loaded above to determine what string the following sequence corresponds to:\n",
        "\n",
        "`[38, 35, 1, 38, 50, 36, 36, 35, 34, 1, 31, 44, 34, 1, 38, 35, 1, 46, 50, 36, 36, 35, 34]`\n",
        "\n",
        "he huffed and he puffed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPvKz2EMMNpO"
      },
      "source": [
        "## Task 2: Implement the layers of the RNN\n",
        "\n",
        "The RNN that you are building consists of 3 layers + the input layer:\n",
        "1. Input Layer: One-hot codes the current mini-batch of sequences.\n",
        "2. Embedding Layer: Essentially a Dense layer, the first layer of the network takes input chars that have `M = vocab_sz` features and embeds them into an `H_e` dimensional space, where `H_e` is the number of neurons in the layer. For example, if the vocabulary is 74 chars and there are 5 neurons in the embedding layer, the chars will be embedded into a 5-dimensional space.\n",
        "3. GRU Layer: This is the recurrent layer that processes data sequentially char-by-char across time steps until the sequence length is reached.\n",
        "4. Dense Layer: A Dense layer configured with softmax activation that is the same as usual, except for with some extra handling for the 3D input that comes in from the GRU layer below `(N, T, H_GRU)`, where `H_GRU` is the number of neurons in the GRU layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO4mmQ2HMNpP"
      },
      "source": [
        "### 2a. Implement `one_hot` and `InputLayer`\n",
        "\n",
        "The `one_hot` function is at the top of in `gru_net.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9EYjQke8MNpP"
      },
      "outputs": [],
      "source": [
        "from gru_net import one_hot, InputLayer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T__FI5adMNpP"
      },
      "source": [
        "#### Test `one_hot`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCaK2PZbMNpP",
        "outputId": "746747ee-dd82-4b77-a580-f159cc0c95ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Three Little Pigs dev x first mini-batch one-hot coded shape=(2, 7, 56)\n",
            "Three Little Pigs dev x first mini-batch one-hot coded shape=(2, 7, 56)\n",
            "Both shapes should be (2, 7, 56)\n",
            "The total number of ones in xh is 14.0 and should be 14.0\n",
            "The total number of ones in yh is 14.0 and should be 14.0\n"
          ]
        }
      ],
      "source": [
        "dev_xh = one_hot(x_pigs[0], len(pigs_dev_vocab))\n",
        "dev_yh = one_hot(y_pigs[0], len(pigs_dev_vocab))\n",
        "\n",
        "print(f'Three Little Pigs dev x first mini-batch one-hot coded shape={dev_xh.shape}')\n",
        "print(f'Three Little Pigs dev x first mini-batch one-hot coded shape={dev_yh.shape}')\n",
        "print('Both shapes should be (2, 7, 56)')\n",
        "\n",
        "print(f'The total number of ones in xh is {tf.reduce_sum(dev_xh)} and should be 14.0')\n",
        "print(f'The total number of ones in yh is {tf.reduce_sum(dev_yh)} and should be 14.0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLnEQeuYMNpQ"
      },
      "source": [
        "#### Test `InputLayer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRlqpNRyMNpQ",
        "outputId": "06679497-9b34-430c-c16a-da5267787fd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input layer activation shape=(2, 7, 56) and it should be (2, 7, 56)\n",
            "The total number of ones is 14.0 and should be 14.0\n"
          ]
        }
      ],
      "source": [
        "test_input_layer = InputLayer(len(pigs_dev_vocab))\n",
        "in_act = test_input_layer.forward(y_pigs[1])\n",
        "\n",
        "print(f'Input layer activation shape={in_act.shape} and it should be (2, 7, 56)')\n",
        "print(f'The total number of ones is {tf.reduce_sum(in_act)} and should be 14.0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "excXpEWJMNpQ"
      },
      "source": [
        "### 2b. Implement `EmbeddingLayer` in `gru_net.py`\n",
        "\n",
        "Now let's implement and testing the Embedding Layer. This consists of the following methods:\n",
        "\n",
        "- Constructor\n",
        "- get+set methods: The get and set methods are important to be able to save your network weights as you train your RNN. This allows you to save your work in case training gets interrupted.\n",
        "- `net_in`\n",
        "- `net_act`\n",
        "- `forward`\n",
        "- `backward`: You can skip this for now, but it will be needed for training later.\n",
        "\n",
        "#### Note about network weight initialization\n",
        "\n",
        "Use He/Kaiming initialization in each layer (*this will dramatically decrease the required training epochs!*). Recall this means initializing the weights from a Normal/Gaussian distribution with mean `0` and standard deviation of $1/\\sqrt{\\text{FanIn}}$ where `FanIn` is the number of neurons in the previous layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GtPC6jMxMNpQ"
      },
      "outputs": [],
      "source": [
        "from gru_net import EmbeddingLayer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBc0fKXxMNpQ"
      },
      "source": [
        "#### Test: Constructor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ1qldqcMNpQ",
        "outputId": "70c2264a-5948-4ae8-9c1d-3bd787c38f59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your embedding wts have shape=(56, 4) and they should be (56, 4)\n",
            "Your embedding wts are a tf Variable (as they should be)? True\n",
            "Your first few embedding wts are\n",
            "[[ 0.20192  0.05652 -0.05608 -0.13845]\n",
            " [-0.16528  0.06284 -0.00187  0.15887]\n",
            " [ 0.08052  0.08014 -0.0943  -0.05786]] and they should be:\n",
            "[[ 0.20192  0.05652 -0.05608 -0.13845]\n",
            " [-0.16528  0.06284 -0.00187  0.15887]\n",
            " [ 0.08052  0.08014 -0.0943  -0.05786]]\n",
            "\n",
            "Your embedding bias is a tf Variable (as it should be)? True\n",
            "Your embedding bias is\n",
            "[ 0.14257  0.026   -0.07094  0.01228] and it should be\n",
            "[ 0.14257  0.026   -0.07094  0.01228]\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "test_input_layer = InputLayer(M=len(pigs_dev_vocab))\n",
        "test_embedding_layer = EmbeddingLayer(embedding_sz=4, num_neurons_prev_layer=len(pigs_dev_vocab))\n",
        "\n",
        "print(f'Your embedding wts have shape={test_embedding_layer.get_wts().shape} and they should be (56, 4)')\n",
        "print(f'Your embedding wts are a tf Variable (as they should be)? {isinstance(test_embedding_layer.get_wts(), tf.Variable)}')\n",
        "print(f'Your first few embedding wts are\\n{test_embedding_layer.get_wts()[:3]} and they should be:')\n",
        "print('''[[ 0.20192  0.05652 -0.05608 -0.13845]\n",
        " [-0.16528  0.06284 -0.00187  0.15887]\n",
        " [ 0.08052  0.08014 -0.0943  -0.05786]]''')\n",
        "\n",
        "print()\n",
        "print(f'Your embedding bias is a tf Variable (as it should be)? {isinstance(test_embedding_layer.get_bias(), tf.Variable)}')\n",
        "print(f'Your embedding bias is\\n{test_embedding_layer.get_bias().numpy()} and it should be')\n",
        "print('[ 0.14257  0.026   -0.07094  0.01228]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG5VZIwrMNpR"
      },
      "source": [
        "#### Test: `forward`\n",
        "\n",
        "This also tests your `net_in` and `net_act`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh9aQCK6MNpR",
        "outputId": "d5cf1456-4517-48af-8948-38c5f22e0126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your embedding net_acts have shape (2, 7, 4) and they have shape=(2, 7, 4).\n",
            "Your first few net_acts are\n",
            "[ 0.14183 -0.14003 -0.34781 -0.02254 -0.00081] and should be\n",
            "[ 0.14183 -0.14003 -0.34781 -0.02254 -0.00081]\n",
            "Your last few net_acts are\n",
            "[ 0.04641 -0.02271  0.08884 -0.0728   0.17115] and should be\n",
            "[ 0.04641 -0.02271  0.08884 -0.0728   0.17115]\n"
          ]
        }
      ],
      "source": [
        "embed_acts = test_embedding_layer.forward(test_input_layer.forward(x_pigs[0]))\n",
        "\n",
        "print(f'Your embedding net_acts have shape {embed_acts.shape} and they have shape=(2, 7, 4).')\n",
        "print(f'Your first few net_acts are\\n{tf.reshape(embed_acts, -1)[:5]} and should be\\n[ 0.14183 -0.14003 -0.34781 -0.02254 -0.00081]')\n",
        "print(f'Your last few net_acts are\\n{tf.reshape(embed_acts, -1)[-5:]} and should be\\n[ 0.04641 -0.02271  0.08884 -0.0728   0.17115]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5wx9w4FMNpR"
      },
      "source": [
        "### 2c. Implement `GRULayer` constructor, get, set, and state methods\n",
        "\n",
        "Remember that there are 3 sets of weights/biases for:\n",
        "1. Update gate\n",
        "2. Reset gate\n",
        "3. Candidate activation\n",
        "\n",
        "Each item above requires 3 sets of parameters:\n",
        "1. Input -> Curr Layer (feedforward) weights\n",
        "2. Curr Layer -> Curr layer (recurrent) weights\n",
        "3. Bias\n",
        "\n",
        "**Note:** Use He/Kaiming initialization the same way for the input weights and bias. Also use it for the recurrent weights, but `FanIn` becomes the number of neurons in the *current* layer (`H`).\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qFkwibw0MNpR"
      },
      "outputs": [],
      "source": [
        "from gru_net import GRULayer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXMti8joMNpR"
      },
      "source": [
        "#### Test: GRU weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZjM6Ov1MNpR",
        "outputId": "045b1029-9bbc-46a8-935f-d7f74d479085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Update Gate test...\n",
            "Your GRU update i2h wts have shape=(3, 4) and they should be (3, 4)\n",
            "Your GRU update i2h wts are a tf Variable (as they should be)? True\n",
            "Your first few GRU update i2h wts are\n",
            "[[ 0.87241  0.24417 -0.24231 -0.59816]\n",
            " [-0.71408  0.27151 -0.00807  0.68639]\n",
            " [ 0.34787  0.34624 -0.40744 -0.24998]] and they should be:\n",
            "[[ 0.87241  0.24417 -0.24231 -0.59816]\n",
            " [-0.71408  0.27151 -0.00807  0.68639]\n",
            " [ 0.34787  0.34624 -0.40744 -0.24998]]\n",
            "Your GRU update h2h wts have shape=(4, 4) and they should be (4, 4)\n",
            "Your GRU update h2h wts are a tf Variable (as they should be)? True\n",
            "Your first few GRU update h2h wts are\n",
            "[[ 0.53344  0.09727 -0.26541  0.04595]\n",
            " [-0.08877 -0.45965 -1.03888  1.0196 ]\n",
            " [ 0.40145 -0.46545 -0.18622 -0.16049]] and they should be:\n",
            "[[ 0.53344  0.09727 -0.26541  0.04595]\n",
            " [-0.08877 -0.45965 -1.03888  1.0196 ]\n",
            " [ 0.40145 -0.46545 -0.18622 -0.16049]]\n",
            "Your GRU update bias have shape=(4,) and they should be (4,)\n",
            "Your GRU update bias are a tf Variable (as they should be)? True\n",
            "Your first few GRU update bias are\n",
            "[-0.90206 -0.05577 -0.42278] and they should be:\n",
            "[-0.90206 -0.05577 -0.42278]\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "test_gru_layer = GRULayer(4, 3)\n",
        "\n",
        "print('Update Gate test...')\n",
        "i2h, h2h, b = test_gru_layer.get_update_gate_wts_b()\n",
        "\n",
        "print(f'Your GRU update i2h wts have shape={i2h.shape} and they should be (3, 4)')\n",
        "print(f'Your GRU update i2h wts are a tf Variable (as they should be)? {isinstance(i2h, tf.Variable)}')\n",
        "print(f'Your first few GRU update i2h wts are\\n{i2h[:3]} and they should be:')\n",
        "print('''[[ 0.87241  0.24417 -0.24231 -0.59816]\n",
        " [-0.71408  0.27151 -0.00807  0.68639]\n",
        " [ 0.34787  0.34624 -0.40744 -0.24998]]''')\n",
        "\n",
        "print(f'Your GRU update h2h wts have shape={h2h.shape} and they should be (4, 4)')\n",
        "print(f'Your GRU update h2h wts are a tf Variable (as they should be)? {isinstance(h2h, tf.Variable)}')\n",
        "print(f'Your first few GRU update h2h wts are\\n{h2h[:3]} and they should be:')\n",
        "print('''[[ 0.53344  0.09727 -0.26541  0.04595]\n",
        " [-0.08877 -0.45965 -1.03888  1.0196 ]\n",
        " [ 0.40145 -0.46545 -0.18622 -0.16049]]''')\n",
        "\n",
        "print(f'Your GRU update bias have shape={b.shape} and they should be (4,)')\n",
        "print(f'Your GRU update bias are a tf Variable (as they should be)? {isinstance(b, tf.Variable)}')\n",
        "print(f'Your first few GRU update bias are\\n{b[:3]} and they should be:')\n",
        "print('''[-0.90206 -0.05577 -0.42278]''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti33dz4rMNpS",
        "outputId": "8390b671-ccc4-4bdf-a1ec-65e78ac2f548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reset Gate test...\n",
            "Your GRU reset i2h wts have shape=(3, 4) and they should be (3, 4)\n",
            "Your GRU reset i2h wts are a tf Variable (as they should be)? True\n",
            "Your first few GRU reset i2h wts are\n",
            "[[ 0.9809  -0.44642  0.16021 -0.2799 ]\n",
            " [ 0.96975  0.14976 -0.51416  0.27798]\n",
            " [ 0.03932 -0.58443  0.65193 -1.0039 ]] and they should be:\n",
            "[[ 0.9809  -0.44642  0.16021 -0.2799 ]\n",
            " [ 0.96975  0.14976 -0.51416  0.27798]\n",
            " [ 0.03932 -0.58443  0.65193 -1.0039 ]] \n",
            "Your GRU reset h2h wts have shape=(4, 4) and they should be (4, 4)\n",
            "Your GRU reset h2h wts are a tf Variable (as they should be)? True\n",
            "Your first few GRU reset h2h wts are\n",
            "[[ 0.80699  1.22477 -0.57651 -0.16718]\n",
            " [-0.24433 -0.67496  0.20438 -0.37776]\n",
            " [ 0.60964  0.64307  0.20514  0.7305 ]] and they should be:\n",
            "[[ 0.807    1.22477 -0.57651 -0.16718]\n",
            " [-0.24433 -0.67496  0.20438 -0.37776]\n",
            " [ 0.60964  0.64307  0.20514  0.7305 ]]\n",
            "Your GRU reset bias have shape=(4,) and they should be (4,)\n",
            "Your GRU reset bias are a tf Variable (as they should be)? True\n",
            "Your first few GRU reset bias are\n",
            "[-0.58727 -0.34153 -0.11044] and they should be:\n",
            "[-0.58727 -0.34153 -0.11044]\n"
          ]
        }
      ],
      "source": [
        "print('Reset Gate test...')\n",
        "i2h, h2h, b = test_gru_layer.get_reset_gate_wts_b()\n",
        "\n",
        "print(f'Your GRU reset i2h wts have shape={i2h.shape} and they should be (3, 4)')\n",
        "print(f'Your GRU reset i2h wts are a tf Variable (as they should be)? {isinstance(i2h, tf.Variable)}')\n",
        "print(f'Your first few GRU reset i2h wts are\\n{i2h[:3]} and they should be:')\n",
        "print('''[[ 0.9809  -0.44642  0.16021 -0.2799 ]\n",
        " [ 0.96975  0.14976 -0.51416  0.27798]\n",
        " [ 0.03932 -0.58443  0.65193 -1.0039 ]] ''')\n",
        "\n",
        "print(f'Your GRU reset h2h wts have shape={h2h.shape} and they should be (4, 4)')\n",
        "print(f'Your GRU reset h2h wts are a tf Variable (as they should be)? {isinstance(h2h, tf.Variable)}')\n",
        "print(f'Your first few GRU reset h2h wts are\\n{h2h[:3]} and they should be:')\n",
        "print('''[[ 0.807    1.22477 -0.57651 -0.16718]\n",
        " [-0.24433 -0.67496  0.20438 -0.37776]\n",
        " [ 0.60964  0.64307  0.20514  0.7305 ]]''')\n",
        "\n",
        "print(f'Your GRU reset bias have shape={b.shape} and they should be (4,)')\n",
        "print(f'Your GRU reset bias are a tf Variable (as they should be)? {isinstance(b, tf.Variable)}')\n",
        "print(f'Your first few GRU reset bias are\\n{b[:3]} and they should be:')\n",
        "print('''[-0.58727 -0.34153 -0.11044]''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooTd8xZoMNpS",
        "outputId": "41f5d177-4a02-4274-d041-4fdede40dbb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Canidate activation test...\n",
            "Your GRU candidate i2h wts have shape=(3, 4) and they should be (3, 4)\n",
            "Your GRU candidate i2h wts are a tf Variable (as they should be)? True\n",
            "Your first few GRU candidate i2h wts are\n",
            "[[ 1.29817  0.52123  0.01139  0.13645]\n",
            " [-0.61715 -0.91416 -0.03451 -0.04016]\n",
            " [-0.83262  0.71733 -0.84149  0.87591]] and they should be:\n",
            "[[ 1.29817  0.52123  0.01139  0.13645]\n",
            " [-0.61715 -0.91416 -0.03451 -0.04016]\n",
            " [-0.83262  0.71733 -0.84149  0.87591]] \n",
            "Your GRU candidate h2h wts have shape=(4, 4) and they should be (4, 4)\n",
            "Your GRU candidate h2h wts are a tf Variable (as they should be)? True\n",
            "Your first few GRU candidate h2h wts are\n",
            "[[-0.28515  0.21237  0.01064 -0.3059 ]\n",
            " [-0.36389 -0.77809  0.23165  0.30191]\n",
            " [-0.59597 -0.19133 -0.21834  0.04076]] and they should be:\n",
            "[[-0.28515  0.21237  0.01064 -0.3059 ]\n",
            " [-0.36389 -0.77809  0.23165  0.30191]\n",
            " [-0.59597 -0.19133 -0.21834  0.04076]]\n",
            "Your GRU candidate bias have shape=(4,) and they should be (4,)\n",
            "Your GRU candidate bias are a tf Variable (as they should be)? True\n",
            "Your first few GRU candidate bias are\n",
            "[ 0.41641  0.38124 -0.15264] and they should be:\n",
            "[ 0.41641  0.38124 -0.15264]\n"
          ]
        }
      ],
      "source": [
        "print('Canidate activation test...')\n",
        "i2h, h2h, b = test_gru_layer.get_candidate_wts_b()\n",
        "\n",
        "print(f'Your GRU candidate i2h wts have shape={i2h.shape} and they should be (3, 4)')\n",
        "print(f'Your GRU candidate i2h wts are a tf Variable (as they should be)? {isinstance(i2h, tf.Variable)}')\n",
        "print(f'Your first few GRU candidate i2h wts are\\n{i2h[:3]} and they should be:')\n",
        "print('''[[ 1.29817  0.52123  0.01139  0.13645]\n",
        " [-0.61715 -0.91416 -0.03451 -0.04016]\n",
        " [-0.83262  0.71733 -0.84149  0.87591]] ''')\n",
        "\n",
        "print(f'Your GRU candidate h2h wts have shape={h2h.shape} and they should be (4, 4)')\n",
        "print(f'Your GRU candidate h2h wts are a tf Variable (as they should be)? {isinstance(h2h, tf.Variable)}')\n",
        "print(f'Your first few GRU candidate h2h wts are\\n{h2h[:3]} and they should be:')\n",
        "print('''[[-0.28515  0.21237  0.01064 -0.3059 ]\n",
        " [-0.36389 -0.77809  0.23165  0.30191]\n",
        " [-0.59597 -0.19133 -0.21834  0.04076]]''')\n",
        "\n",
        "print(f'Your GRU candidate bias have shape={b.shape} and they should be (4,)')\n",
        "print(f'Your GRU candidate bias are a tf Variable (as they should be)? {isinstance(b, tf.Variable)}')\n",
        "print(f'Your first few GRU candidate bias are\\n{b[:3]} and they should be:')\n",
        "print('''[ 0.41641  0.38124 -0.15264]''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru_2gW2cMNpS"
      },
      "source": [
        "#### Test: State methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4DFclGFMNpS",
        "outputId": "e747347b-9ed1-4be1-d64c-ed32bdb0ccf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GRU initial state shape=(2, 4) and should be (2, 4)\n",
            "Values correct? True\n",
            "After setting last state.\n",
            "GRU initial state shape=(2, 4) and should be (2, 4)\n",
            "Values correct? True\n",
            "Resetting GRU last state...\n",
            "GRU last state shape=(8, 4) and should be (8, 4)\n",
            "Values correct? True\n",
            "GRU last state shape=(9, 4) and should be (9, 4)\n",
            "Values correct? True\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "test_gru_layer = GRULayer(4, 3)\n",
        "test_state = test_gru_layer.get_initial_state(2)\n",
        "print(f'GRU initial state shape={test_state.shape} and should be (2, 4)')\n",
        "print(f'Values correct? {tf.reduce_all(test_state == 0)}')\n",
        "test_gru_layer.set_last_state(tf.random.uniform(shape=test_state.shape))\n",
        "print('After setting last state.')\n",
        "test_state = test_gru_layer.get_initial_state(2)\n",
        "print(f'GRU initial state shape={test_state.shape} and should be (2, 4)')\n",
        "print(f'Values correct? {tf.reduce_all(test_state == 0)}')\n",
        "print('Resetting GRU last state...')\n",
        "test_gru_layer.reset_state(8)\n",
        "test_state = test_gru_layer.get_last_state(2)\n",
        "print(f'GRU last state shape={test_state.shape} and should be (8, 4)')\n",
        "print(f'Values correct? {tf.reduce_all(test_state == 0)}')\n",
        "\n",
        "tf.random.set_seed(0)\n",
        "test_gru_layer = GRULayer(4, 3)\n",
        "test_state = test_gru_layer.get_last_state(9)\n",
        "print(f'GRU last state shape={test_state.shape} and should be (9, 4)')\n",
        "print(f'Values correct? {tf.reduce_all(test_state == 0)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIJTkcbqMNpS"
      },
      "source": [
        "### 2d. Implement `GRULayer` `net_in` and `net_act`   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI8kR1m3MNpS"
      },
      "source": [
        "#### Test: `net_in`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iAdM5tRMNpS",
        "outputId": "7c059ae9-78c8-4e35-d830-65add0340e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your update gate net_in shape is (5, 3) and it should be (5, 3).\n",
            "Your update gate net_in 1st few values are\n",
            "[-1.44717  1.04781 -0.34782 -0.97264] and they should be\n",
            "[-1.44717  1.04781 -0.34782 -0.97264].\n",
            "Your reset gate net_in shape is (5, 3) and it should be (5, 3).\n",
            "Your reset gate net_in 1st few values are\n",
            "[-0.32367  0.45778 -0.4633  -0.51985] and they should be\n",
            "[-0.32367  0.45778 -0.4633  -0.51985].\n",
            "Your candidate net_in shape is (5, 3) and it should be (5, 3).\n",
            "Your candidate net_in 1st few values are\n",
            "[ 1.16616  0.03398 -0.29721  1.65007] and they should be\n",
            "[ 1.16616  0.03398 -0.29721  1.65007].\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "test_gru_layer = GRULayer(3, 4)\n",
        "tf.random.set_seed(0)\n",
        "test_x = tf.random.uniform(shape=(5, 4))\n",
        "test_prev_act = tf.random.uniform(shape=(5, 3))\n",
        "u, r, c = test_gru_layer.net_in(test_x, test_prev_act)\n",
        "print(f'Your update gate net_in shape is {u.shape} and it should be (5, 3).')\n",
        "print(f'Your update gate net_in 1st few values are\\n{tf.reshape(u, -1)[:4]} and they should be\\n[-1.44717  1.04781 -0.34782 -0.97264].')\n",
        "print(f'Your reset gate net_in shape is {r.shape} and it should be (5, 3).')\n",
        "print(f'Your reset gate net_in 1st few values are\\n{tf.reshape(r, -1)[:4]} and they should be\\n[-0.32367  0.45778 -0.4633  -0.51985].')\n",
        "print(f'Your candidate net_in shape is {c.shape} and it should be (5, 3).')\n",
        "print(f'Your candidate net_in 1st few values are\\n{tf.reshape(c, -1)[:4]} and they should be\\n[ 1.16616  0.03398 -0.29721  1.65007].')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2HIwtsQMNpT"
      },
      "source": [
        "#### Test: `net_act`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKMmEEqKMNpT",
        "outputId": "299fa099-63ff-4bb6-c3ec-e7d676804b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your update gate net_act shape is (5, 3) and it should be (5, 3).\n",
            "Your update gate net_act 1st few values are\n",
            "[0.60415 0.16816 0.27142 0.80665] and they should be\n",
            "[0.60415 0.16816 0.27142 0.80665].\n",
            "Your reset gate net_act shape is (5, 3) and it should be (5, 3).\n",
            "Your reset gate net_act 1st few values are\n",
            "[0.19044 0.74036 0.41391 0.27436] and they should be\n",
            "[0.19044 0.74036 0.41391 0.27436].\n",
            "Your candidate net_act shape is (5, 3) and it should be (5, 3).\n",
            "Your candidate net_act 1st few values are\n",
            "[0.41978 0.61249 0.3862  0.37289] and they should be\n",
            "[0.41978 0.61249 0.3862  0.37289].\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "test_gru_layer = GRULayer(3, 4)\n",
        "tf.random.set_seed(0)\n",
        "test_x = tf.random.uniform(shape=(5, 4))\n",
        "test_prev_act = tf.random.uniform(shape=(5, 3))\n",
        "u, r, c = test_gru_layer.net_in(test_x, test_prev_act)\n",
        "u, r, c = test_gru_layer.net_act(u, r, c, test_prev_act)\n",
        "\n",
        "print(f'Your update gate net_act shape is {u.shape} and it should be (5, 3).')\n",
        "print(f'Your update gate net_act 1st few values are\\n{tf.reshape(u, -1)[:4]} and they should be\\n[0.60415 0.16816 0.27142 0.80665].')\n",
        "print(f'Your reset gate net_act shape is {r.shape} and it should be (5, 3).')\n",
        "print(f'Your reset gate net_act 1st few values are\\n{tf.reshape(r, -1)[:4]} and they should be\\n[0.19044 0.74036 0.41391 0.27436].')\n",
        "print(f'Your candidate net_act shape is {c.shape} and it should be (5, 3).')\n",
        "print(f'Your candidate net_act 1st few values are\\n{tf.reshape(c, -1)[:4]} and they should be\\n[0.41978 0.61249 0.3862  0.37289].')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5f2As79MNpT"
      },
      "source": [
        "#### Test: `forward`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdZ1c0BfMNpT",
        "outputId": "f3af4a71-21cb-44eb-e583-8ba6afdc590a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After 1 time step, your netAct looks like:\n",
            "[[ 0.60415  0.16816  0.27142]\n",
            " [ 0.80665 -0.00165  0.13353]\n",
            " [ 0.2769   0.35341  0.13801]\n",
            " [ 0.51053  0.27325  0.23583]\n",
            " [ 0.28963  0.52395 -0.23419]]\n",
            "and it should be:\n",
            "[[ 0.60415  0.16816  0.27142]\n",
            " [ 0.80665 -0.00165  0.13353]\n",
            " [ 0.2769   0.35341  0.13801]\n",
            " [ 0.51053  0.27325  0.23583]\n",
            " [ 0.28963  0.52395 -0.23419]]\n",
            "Now processing same mini-batch again afterwards...\n",
            "After 1 time step, your netAct looks like:\n",
            "[[ 0.66495  0.11161  0.02625]\n",
            " [ 0.84713 -0.18556 -0.05147]\n",
            " [ 0.54     0.22563 -0.05024]\n",
            " [ 0.64844  0.14146  0.01014]\n",
            " [ 0.56365  0.40479 -0.44451]]\n",
            "and it should be:\n",
            "[[ 0.66495  0.11161  0.02625]\n",
            " [ 0.84713 -0.18556 -0.05147]\n",
            " [ 0.54     0.22563 -0.05024]\n",
            " [ 0.64844  0.14146  0.01014]\n",
            " [ 0.56365  0.40479 -0.44451]]\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "test_gru_layer = GRULayer(3, 4)\n",
        "tf.random.set_seed(0)\n",
        "test_x = tf.random.uniform(shape=(5, 1, 4))\n",
        "test_prev_act = tf.random.uniform(shape=(5, 3))\n",
        "test_gru_layer.set_last_state(test_prev_act)\n",
        "test_act_1 = test_gru_layer.forward(test_x)\n",
        "print(f'After 1 time step, your netAct looks like:\\n{tf.squeeze(test_act_1)}')\n",
        "print('and it should be:')\n",
        "print('''[[ 0.60415  0.16816  0.27142]\n",
        " [ 0.80665 -0.00165  0.13353]\n",
        " [ 0.2769   0.35341  0.13801]\n",
        " [ 0.51053  0.27325  0.23583]\n",
        " [ 0.28963  0.52395 -0.23419]]''')\n",
        "\n",
        "print('Now processing same mini-batch again afterwards...')\n",
        "test_act_1 = test_gru_layer.forward(test_x)\n",
        "print(f'After 1 time step, your netAct looks like:\\n{tf.squeeze(test_act_1)}')\n",
        "print('and it should be:')\n",
        "print('''[[ 0.66495  0.11161  0.02625]\n",
        " [ 0.84713 -0.18556 -0.05147]\n",
        " [ 0.54     0.22563 -0.05024]\n",
        " [ 0.64844  0.14146  0.01014]\n",
        " [ 0.56365  0.40479 -0.44451]]''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gdb0m5aMNpT",
        "outputId": "472a9578-ce7c-4998-f127-bc005008a789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now processing a 2 time step mini-batch...\n",
            "After 1 time steps, first few netActs looks like:\n",
            "[ 0.26164  0.0169  -0.11167  0.37683  0.09779 -0.10014  0.31172]\n",
            "and they should be:\n",
            "[ 0.26164  0.0169  -0.11167  0.37683  0.09779 -0.10014  0.31172]\n",
            "After 2 time steps, first few netActs looks like:\n",
            "[ 0.50342 -0.16098 -0.20759  0.60492  0.06678 -0.16809  0.56816]\n",
            "and they should be:\n",
            "[ 0.50342 -0.16098 -0.20759  0.60492  0.06678 -0.16809  0.56816]\n",
            "\n",
            "Now processing a 6 time step mini-batch...\n",
            "After 6 time steps, first few netActs looks like:\n",
            "[ 0.50342 -0.16098 -0.20759  0.60492  0.06678 -0.16809  0.56816]\n",
            "and they should be:\n",
            "[ 0.50342 -0.16098 -0.20759  0.60492  0.06678 -0.16809  0.56816]\n"
          ]
        }
      ],
      "source": [
        "print('Now processing a 2 time step mini-batch...')\n",
        "tf.random.set_seed(0)\n",
        "test_gru_layer = GRULayer(3, 4)\n",
        "tf.random.set_seed(0)\n",
        "test_x = tf.random.uniform(shape=(5, 2, 4))\n",
        "test_act_2 = test_gru_layer.forward(test_x)\n",
        "print(f'After 1 time steps, first few netActs looks like:\\n{tf.reshape(test_act_2[:, 0], -1)[:7]}')\n",
        "print('and they should be:\\n[ 0.26164  0.0169  -0.11167  0.37683  0.09779 -0.10014  0.31172]')\n",
        "print(f'After 2 time steps, first few netActs looks like:\\n{tf.reshape(test_act_2[:, 1], -1)[:7]}')\n",
        "print('and they should be:\\n[ 0.50342 -0.16098 -0.20759  0.60492  0.06678 -0.16809  0.56816]')\n",
        "\n",
        "print()\n",
        "print('Now processing a 6 time step mini-batch...')\n",
        "tf.random.set_seed(0)\n",
        "test_gru_layer = GRULayer(3, 4)\n",
        "tf.random.set_seed(0)\n",
        "test_x = tf.random.uniform(shape=(2, 6, 4))\n",
        "test_act_6 = test_gru_layer.forward(test_x)\n",
        "print(f'After 6 time steps, first few netActs looks like:\\n{tf.reshape(test_act_2[:, -1], -1)[:7]}')\n",
        "print('and they should be:\\n[ 0.50342 -0.16098 -0.20759  0.60492  0.06678 -0.16809  0.56816]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZc6EkwTMNpU"
      },
      "source": [
        "### 2e. Implement `DenseLayer` in `gru_net.py`\n",
        "\n",
        "Uses softmax activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zHAJ_lC9MNpY"
      },
      "outputs": [],
      "source": [
        "from gru_net import DenseLayer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMEQP6_KMNpY"
      },
      "source": [
        "#### Test: Constructor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sknlj-jzMNpY",
        "outputId": "1bae5e02-3b98-431a-994f-57fc2665c7f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your dense wts have shape=(3, 5) and they should be (3, 5)\n",
            "Your dense wts are a tf Variable (as they should be)? True\n",
            "Your first few dense wts are\n",
            "[[ 0.87241  0.24417 -0.24231 -0.59816 -0.71408]\n",
            " [ 0.27151 -0.00807  0.68639  0.34787  0.34624]\n",
            " [-0.40744 -0.24998  0.4582  -0.4027  -0.55416]] and they should be:\n",
            "[[ 0.87241  0.24417 -0.24231 -0.59816 -0.71408]\n",
            " [ 0.27151 -0.00807  0.68639  0.34787  0.34624]\n",
            " [-0.40744 -0.24998  0.4582  -0.4027  -0.55416]]\n",
            "\n",
            "Your dense bias is a tf Variable (as it should be)? True\n",
            "Your dense bias is\n",
            "[ 0.47712  0.08701 -0.23739  0.0411  -0.0794 ] and it should be\n",
            "[ 0.47712  0.08701 -0.23739  0.0411  -0.0794 ]\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "test_dense_layer = DenseLayer(5, 3)\n",
        "\n",
        "print(f'Your dense wts have shape={test_dense_layer.get_wts().shape} and they should be (3, 5)')\n",
        "print(f'Your dense wts are a tf Variable (as they should be)? {isinstance(test_dense_layer.get_wts(), tf.Variable)}')\n",
        "print(f'Your first few dense wts are\\n{test_dense_layer.get_wts()[:3]} and they should be:')\n",
        "print('''[[ 0.87241  0.24417 -0.24231 -0.59816 -0.71408]\n",
        " [ 0.27151 -0.00807  0.68639  0.34787  0.34624]\n",
        " [-0.40744 -0.24998  0.4582  -0.4027  -0.55416]]''')\n",
        "\n",
        "print()\n",
        "print(f'Your dense bias is a tf Variable (as it should be)? {isinstance(test_dense_layer.get_bias(), tf.Variable)}')\n",
        "print(f'Your dense bias is\\n{test_dense_layer.get_bias().numpy()} and it should be')\n",
        "print('[ 0.47712  0.08701 -0.23739  0.0411  -0.0794 ]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab88Ek6cMNpZ"
      },
      "source": [
        "#### Test: `forward`\n",
        "\n",
        "This also tests your `net_in` and `net_act`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbeCbHa_MNpZ",
        "outputId": "12234ff9-8bd5-4944-c7dc-1104e0d64e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your embedding net_acts have shape (2, 7, 5) and they should have shape=(2, 7, 5).\n",
            "Your first few net_acts are\n",
            "[ 0.56979  0.0228   0.07896 -0.27729 -0.51306] and should be\n",
            "[ 0.56979  0.02279  0.07896 -0.27729 -0.51306]\n",
            "Your last few net_acts are\n",
            "[ 0.38018 -0.03075  0.07304 -0.25385 -0.48275] and should be\n",
            "[ 0.38018 -0.03075  0.07304 -0.25385 -0.48275]\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "x_test_dense = tf.random.uniform((2, 7, 3))\n",
        "dense_acts = test_dense_layer.forward(x_test_dense)\n",
        "\n",
        "print(f'Your embedding net_acts have shape {dense_acts.shape} and they should have shape=(2, 7, 5).')\n",
        "print(f'Your first few net_acts are\\n{tf.reshape(dense_acts, -1)[:5]} and should be\\n[ 0.56979  0.02279  0.07896 -0.27729 -0.51306]')\n",
        "print(f'Your last few net_acts are\\n{tf.reshape(dense_acts, -1)[-5:]} and should be\\n[ 0.38018 -0.03075  0.07304 -0.25385 -0.48275]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVp99v6IMNpZ"
      },
      "source": [
        "## Task 3: Implement Recurrent Neural Network (RNN)\n",
        "\n",
        "The RNN is composed of all the layers that you implemented:\n",
        "1. Input layer (*identity activation*)\n",
        "2. Embedding layer (*identity activation*)\n",
        "3. GRU layer (*GRU activations â€” i.e. sigmoid + tanh*)\n",
        "4. Dense layer (*softmax activation*)\n",
        "\n",
        "### 3a. Start implementing the `RNN` class\n",
        "\n",
        "For now focus on the following methods of the `RNN` class:\n",
        "- Constructor\n",
        "- Get methods\n",
        "- Set methods\n",
        "- forward\n",
        "- loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oQByHuROMNpZ"
      },
      "outputs": [],
      "source": [
        "from gru_net import RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELC3r6ryMNpZ"
      },
      "source": [
        "#### Test: RNN `forward` (1/2) Fake data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOBYsd93MNpZ",
        "outputId": "b5e52163-5611-4a36-a686-89e20690b870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of dimensions of the output layer net_in=3 (should be 3) with\n",
            "B=2, T=6, M/C=7. It should be:\n",
            "B=2, T=6, M/C=7\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "test_input = tf.random.uniform((2, 6), maxval=10, dtype=tf.int64)\n",
        "test_rnn = RNN(7, 4, 3)\n",
        "test_out = test_rnn.forward(test_input)\n",
        "print(f'The number of dimensions of the output layer net_in={len(test_out.shape)} (should be 3) with')\n",
        "print(f'B={test_out.shape[0]}, T={test_out.shape[1]}, M/C={test_out.shape[2]}. It should be:')\n",
        "print('B=2, T=6, M/C=7')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tat8hfj1MNpa"
      },
      "source": [
        "#### Test: RNN `forward` (2/2) Little Pigs mini-batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBmWJmC3MNpa",
        "outputId": "f587c811-4bc7-4981-82ec-7d230a0ef592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of dimensions of the output layer net_in=3 (should be 3) with\n",
            "B=2, T=7, M/C=56. It should be:\n",
            "B=2, T=7, M/C=56\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "test_rnn = RNN(len(pigs_dev_vocab), 5, 4)\n",
        "test_out_pig = test_rnn.forward(x_pigs[2])\n",
        "print(f'The number of dimensions of the output layer net_in={len(test_out_pig.shape)} (should be 3) with')\n",
        "print(f'B={test_out_pig.shape[0]}, T={test_out_pig.shape[1]}, M/C={test_out_pig.shape[2]}. It should be:')\n",
        "print('B=2, T=7, M/C=56')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBOTGw5AMNpa"
      },
      "source": [
        "#### Test: `loss`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyXZ7GukMNpa",
        "outputId": "34105525-123c-485d-d766-6a46fea8e837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your loss is 4.3301 and it should be 4.3301.\n"
          ]
        }
      ],
      "source": [
        "test_loss = test_rnn.loss(test_out_pig, y_pigs[2])\n",
        "print(f'Your loss is {test_loss:.4f} and it should be 4.3301.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26_ZJAmLMNpa"
      },
      "source": [
        "### 3b. Implement `fit` and `backward`\n",
        "\n",
        "In the cell below, create a `RNN` object and train **on only the first two Little Pigs mini-batches** with default hyperparameters except for the following:\n",
        "- embedding size: 10\n",
        "- number of GRU neurons: 5\n",
        "- epochs: 50\n",
        "- learning rate: 1e-1\n",
        "\n",
        "Then **make a well-labeled plot** of the average training loss over the 50 epochs.\n",
        "\n",
        "#### Notes\n",
        "\n",
        "- After 1 epoch, your average loss over the 2 mini-batches should be approximately `4.355`.\n",
        "- After 50 epochs, your average loss over the 2 mini-batches should be approximately `0.546`.\n",
        "- Your loss curve should look \"very nice\".\n",
        "- This should take less than 1 minute on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAlZCLFVMNpa",
        "outputId": "47d37804-01aa-4a5e-9bef-075bfb863ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:  0  average loss:  4.0200371742248535\n",
            "epoch:  1  average loss:  3.372244119644165\n",
            "epoch:  2  average loss:  2.916116714477539\n",
            "epoch:  3  average loss:  2.5001401901245117\n",
            "epoch:  4  average loss:  2.2499325275421143\n",
            "epoch:  5  average loss:  2.079658031463623\n",
            "epoch:  6  average loss:  1.8355965614318848\n",
            "epoch:  7  average loss:  1.6742463111877441\n",
            "epoch:  8  average loss:  1.4637486934661865\n",
            "epoch:  9  average loss:  1.3260858058929443\n",
            "epoch:  10  average loss:  1.2027168273925781\n",
            "epoch:  11  average loss:  1.1304171085357666\n",
            "epoch:  12  average loss:  1.0586391687393188\n",
            "epoch:  13  average loss:  0.9877351522445679\n",
            "epoch:  14  average loss:  0.9024575352668762\n",
            "epoch:  15  average loss:  0.8423343896865845\n",
            "epoch:  16  average loss:  0.8173807859420776\n",
            "epoch:  17  average loss:  0.9857097268104553\n",
            "epoch:  18  average loss:  0.6774422526359558\n",
            "epoch:  19  average loss:  0.7510151863098145\n",
            "epoch:  20  average loss:  0.6404175162315369\n",
            "epoch:  21  average loss:  0.6946060657501221\n",
            "epoch:  22  average loss:  0.6984223127365112\n",
            "epoch:  23  average loss:  0.8215287327766418\n",
            "epoch:  24  average loss:  0.7617315053939819\n",
            "epoch:  25  average loss:  1.0808131694793701\n",
            "epoch:  26  average loss:  0.7291756868362427\n",
            "epoch:  27  average loss:  0.962114691734314\n",
            "epoch:  28  average loss:  0.8115674257278442\n",
            "epoch:  29  average loss:  0.7912676334381104\n",
            "epoch:  30  average loss:  0.6469659209251404\n",
            "epoch:  31  average loss:  0.7722290754318237\n",
            "epoch:  32  average loss:  0.9378888607025146\n",
            "epoch:  33  average loss:  0.7616416215896606\n",
            "epoch:  34  average loss:  0.6983639001846313\n",
            "epoch:  35  average loss:  0.6558927297592163\n",
            "epoch:  36  average loss:  0.6298552751541138\n",
            "epoch:  37  average loss:  0.6068493127822876\n",
            "epoch:  38  average loss:  0.5978456735610962\n",
            "epoch:  39  average loss:  0.5959745645523071\n",
            "epoch:  40  average loss:  0.5865871906280518\n",
            "epoch:  41  average loss:  0.6321715712547302\n",
            "epoch:  42  average loss:  0.5926468968391418\n",
            "epoch:  43  average loss:  0.5604071617126465\n",
            "epoch:  44  average loss:  0.562968373298645\n",
            "epoch:  45  average loss:  0.5587003827095032\n",
            "epoch:  46  average loss:  0.5431860089302063\n",
            "epoch:  47  average loss:  0.5534505248069763\n",
            "epoch:  48  average loss:  0.5319720506668091\n",
            "epoch:  49  average loss:  0.5387288331985474\n"
          ]
        }
      ],
      "source": [
        "# Keep me\n",
        "tf.random.set_seed(0)\n",
        "test_rnn = RNN(len(pigs_dev_vocab), 10, 5)\n",
        "hist = test_rnn.fit(x_pigs[:2],y_pigs[:2],50,1e-1,print_every_batch=50, filename=data_path+'/pig_wts.npz')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "9aql7-G2MNpa",
        "outputId": "90645421-9c2a-46f9-ec80-62241a14ae93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(hist)\n",
        "plt.title('Loss History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NowzaKm-MNpb"
      },
      "source": [
        "### 3c. Generate sequences from your RNN (prediction)\n",
        "\n",
        "This is where you give your trained RNN a prompt and it iteratively generates a sequence of chars that come afterwards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsB4LMOEMNpb"
      },
      "source": [
        "#### Test: `generate_sequence`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEm6rYdDMNpb",
        "outputId": "6dea868f-a31e-4272-ad8d-aef89c79ca2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the prompt \"pig\", your untrained RNN generated \"pigcl\". It should be \"pigdn\"\n",
            "For the prompt \"Wolf\", your untrained RNN generated \"WolfebPhS\". It should be \"WolfecOjP\"\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(0)\n",
        "pig_rnn_gen_test = RNN(len(pigs_dev_vocab), 5, 4)\n",
        "\n",
        "np.random.seed(0)\n",
        "gen_output = pig_rnn_gen_test.generate_sequence('pig', 2, char2ind_map_pigs, ind2char_map_pigs)\n",
        "print(f'For the prompt \"pig\", your untrained RNN generated \"{gen_output}\". It should be \"pigdn\"')\n",
        "gen_output = pig_rnn_gen_test.generate_sequence('Wolf', 5, char2ind_map_pigs, ind2char_map_pigs)\n",
        "print(f'For the prompt \"Wolf\", your untrained RNN generated \"{gen_output}\". It should be \"WolfecOjP\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIzwhXIDMNpb"
      },
      "source": [
        "## Task 4: Three Little Pigs\n",
        "\n",
        "Let's train your RNN on a different version of the Three Little Pigs story (`pigs_50.npz`). Note that this is DIFFERENT than the dev version you have been working with above. In this version, the sequence length is longer (`50` vs `7`). This allows your RNN to learn richer word context and sentence structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41hWkudQMNpb"
      },
      "source": [
        "### 4a. Load in Three Little Pigs 50 corpus\n",
        "\n",
        "In the cell below, load in the **Three Little Pigs corpus and vocabulary** â€” the \"real\" corpus, NOT the \"dev\" version used above. The sequence length (T) in this case should be `50` and there should be `3` mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2gKGx2XMNpb",
        "outputId": "155ab5f1-8173-4dff-b9b1-382be1bf4844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Three Little Pigs set shape: (3, 25, 50)\n",
            "Three Little Pigs labels shape: (3, 25, 50)\n",
            "Three Little Pigs char2ind map loaded.\n",
            "Three Little Pigs ind2char map loaded.\n"
          ]
        }
      ],
      "source": [
        "pigs = np.load(data_path+'/pigs_50.npz')\n",
        "x_pigs = pigs['x']\n",
        "y_pigs = pigs['y']\n",
        "\n",
        "print(f'Three Little Pigs set shape: {x_pigs.shape}')\n",
        "print(f'Three Little Pigs labels shape: {y_pigs.shape}')\n",
        "\n",
        "with open(data_path+'/pigs_dev_char2ind_map.pkl', 'rb') as file:\n",
        "    char2ind_map_pigs = pickle.load(file)\n",
        "    print('Three Little Pigs char2ind map loaded.')\n",
        "\n",
        "with open(data_path+'/pigs_dev_ind2char_map.pkl', 'rb') as file:\n",
        "    ind2char_map_pigs = pickle.load(file)\n",
        "    print('Three Little Pigs ind2char map loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYA-CuFhMNpc"
      },
      "source": [
        "### 4b. Different training losses\n",
        "\n",
        "Train `4` fresh RNNs **on the Little Pigs 50 corpus**, each with a different number of training epochs, either 5, 25, 50, or 100 epochs. For each network:\n",
        "1. Record the average loss per epoch. After each training run, print out the final loss.\n",
        "2. Give each trained network the prompt `'by the hair'` `5` different times and have it generate five sequence of 100 characters (*i.e. each net generates the next 100 chars after the prompt multiple times so you can see a range of different outputs*).\n",
        "\n",
        "You should use default hyperparameters for each network, except:\n",
        "- embedding size: 20\n",
        "- number of GRU neurons: 50\n",
        "- learning rate: 1e-2\n",
        "\n",
        "**Note:**\n",
        "- From here on, you should definitely train on the GPU.\n",
        "- For the most part, your average loss over each epoch should steadily decrease. *However, note that there will be a good amount of variability if you look at the loss over individual mini-batches.*\n",
        "- Training all 4 networks on the GPU should take 10-15 minutes in total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4k5MHtYMNpc",
        "outputId": "8e77814b-4ad2-4df0-f051-2b1c239edf17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 25, 50)\n",
            "epoch:  0  average loss:  4.065435409545898\n",
            "epoch:  1  average loss:  3.5726661682128906\n",
            "epoch:  2  average loss:  3.2074129581451416\n",
            "epoch:  3  average loss:  3.104961633682251\n",
            "epoch:  4  average loss:  2.9369945526123047\n",
            "by the hairrubnees   snrwndl l,tec\"nee\n",
            "heetidck nl  beeay I,h.aS \"l ,ao s weuhl R,\" be niah hr m'l, h s\n",
            "ianu,ee\n",
            "by the haire veol.oererinethee\n",
            "Libg_ aikegieraernl tly t i.rnea nelowp\n",
            "Pl g A s, tl \"iiTtgeelad Etle P danc   n\n",
            "by the hairedpy ld\n",
            "naeeokr s,uiOun Mg\n",
            " deaWho h,gaiG\"eatlls heuLG  tioIf fur,uEutnho,oi b wedeL\"p,aI tuusma d \"\n",
            "by the hair o\n",
            "n  'l, hom,  baeinTa,l noo, icb d s gaiwi eeeia'au thepelesinaniP rueeoetensn le d,n we\"\n",
            "'ds upe \n",
            "by the hair,e\n",
            "\n",
            "e PaP \n",
            " juyD ley re lbhe,e,he ss Leoyus ya vWi or bel, ebo,Wthntliwya a:c keruf,eree de gd\"dlato\n"
          ]
        }
      ],
      "source": [
        "# Keep me\n",
        "tf.random.set_seed(0)\n",
        "print(x_pigs.shape)\n",
        "test_rnn = RNN(len(pigs_dev_vocab),20, 50)\n",
        "hist = test_rnn.fit(x_pigs,y_pigs,5,1e-2,print_every_batch=50, print_every_epoch=1, filename=data_path+'/pigs2_wts.npz')\n",
        "for i in range(5):\n",
        "    gen_output = test_rnn.generate_sequence('by the hair', 100, char2ind_map_pigs, ind2char_map_pigs)\n",
        "    print(gen_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CPZB0JZMNpc",
        "outputId": "f8fa6ecc-7552-4fa5-945d-ecd1b013a2f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:  0  average loss:  3.765141725540161\n",
            "epoch:  1  average loss:  3.374835968017578\n",
            "epoch:  2  average loss:  3.193831205368042\n",
            "epoch:  3  average loss:  3.132081985473633\n",
            "epoch:  4  average loss:  3.0140535831451416\n",
            "Epochs = 5\n",
            "by the hair Ne bongm,,ite\"\n",
            "i\n",
            "Yet c al:  hint\n",
            "hefw\n",
            "ire,o eei ,alsg wsetftrvt \"bua!tdt le nL   totle\"yPeWx an he \n",
            "by the hair\"eafau  bhiezdlirwsnid  Teenu  iostweT nit efE t e ewer Peanangaef sine dbW o ingu t gdea\"\n",
            "erc.  P P\n",
            "by the hair  t hnd IdeWnmt tcsiymceVcLeiag \" w\n",
            " i tnufWete ta\n",
            ",'rebVstyPupiH \"tIceno ero \"S e hSg wtaL\"e ieMplt\n",
            "by the hairatoWhPs ?\"bnee\n",
            "c At tp h oloet Wld  sesmdTesm\n",
            "itl e but.Egw Pset fadbdPtmlIennaon tedbgheshdaoP, tt \n",
            "by the hairT  t w thd.nVigetfrn p\"t a eoI ao I od.lano w\". agers\"g eS_el tn ugz,e\"Eftpleteso\"o\n",
            "SBen fuPlg\n",
            "el tf\n",
            "epoch:  0  average loss:  3.958171844482422\n",
            "epoch:  1  average loss:  3.4393341541290283\n",
            "epoch:  2  average loss:  3.2453174591064453\n",
            "epoch:  3  average loss:  3.155797243118286\n",
            "epoch:  4  average loss:  3.0578558444976807\n",
            "epoch:  5  average loss:  2.9052650928497314\n",
            "epoch:  6  average loss:  2.7327616214752197\n",
            "epoch:  7  average loss:  2.5493733882904053\n",
            "epoch:  8  average loss:  2.3874871730804443\n",
            "epoch:  9  average loss:  2.2602670192718506\n",
            "epoch:  10  average loss:  2.152256727218628\n",
            "epoch:  11  average loss:  2.048419237136841\n",
            "epoch:  12  average loss:  1.9427663087844849\n",
            "epoch:  13  average loss:  1.8472623825073242\n",
            "epoch:  14  average loss:  1.7564811706542969\n",
            "epoch:  15  average loss:  1.670698642730713\n",
            "epoch:  16  average loss:  1.591094970703125\n",
            "epoch:  17  average loss:  1.5126352310180664\n",
            "epoch:  18  average loss:  1.4363473653793335\n",
            "epoch:  19  average loss:  1.364427924156189\n",
            "epoch:  20  average loss:  1.294927954673767\n",
            "epoch:  21  average loss:  1.2279399633407593\n",
            "epoch:  22  average loss:  1.1650830507278442\n",
            "epoch:  23  average loss:  1.1082143783569336\n",
            "epoch:  24  average loss:  1.059964656829834\n",
            "Epochs = 25\n",
            "by the hair at fir the little Piugk wot fece buid to thar time, he\n",
            "\n",
            "aadte -the Wothean wit to geth r:ow doussen\n",
            "by the hair in she an, whive;ry as at this said, \"Litt he suip to go Noe. So hy chin.\"\n",
            "\n",
            "\"Oh, wit the Whe soup.\"\n",
            "by the hair.\n",
            "THE LTTHE Souw youh he an\" said to the tot mun. san therxokn, And se puff\n",
            "ahy chinny at juft torn \n",
            "by the hair too\n",
            "heriryyyO, ases at oup, end bemow, and bet a Wolf.\n",
            "\n",
            "The to; walt fipl the Wolf came fusr a hur;\n",
            "by the hair time, ace buff and you bling, with of utle Pig me?lew.\"\n",
            "\n",
            "The t thin.\"\n",
            "\n",
            "TPigs,\" said, \"bild be blow \n",
            "epoch:  0  average loss:  3.853478193283081\n",
            "epoch:  1  average loss:  3.4595563411712646\n",
            "epoch:  2  average loss:  3.211533784866333\n",
            "epoch:  3  average loss:  3.0703392028808594\n",
            "epoch:  4  average loss:  2.9387009143829346\n",
            "epoch:  5  average loss:  2.756162405014038\n",
            "epoch:  6  average loss:  2.599513530731201\n",
            "epoch:  7  average loss:  2.4553115367889404\n",
            "epoch:  8  average loss:  2.322737455368042\n",
            "epoch:  9  average loss:  2.200063943862915\n",
            "epoch:  10  average loss:  2.083101987838745\n",
            "epoch:  11  average loss:  1.9694162607192993\n",
            "epoch:  12  average loss:  1.864021897315979\n",
            "epoch:  13  average loss:  1.7669187784194946\n",
            "epoch:  14  average loss:  1.6756128072738647\n",
            "epoch:  15  average loss:  1.5839405059814453\n",
            "epoch:  16  average loss:  1.4994211196899414\n",
            "epoch:  17  average loss:  1.4186639785766602\n",
            "epoch:  18  average loss:  1.3379589319229126\n",
            "epoch:  19  average loss:  1.2582648992538452\n",
            "epoch:  20  average loss:  1.1810624599456787\n",
            "epoch:  21  average loss:  1.107291340827942\n",
            "epoch:  22  average loss:  1.0374864339828491\n",
            "epoch:  23  average loss:  0.9756210446357727\n",
            "epoch:  24  average loss:  0.9338995814323425\n",
            "epoch:  25  average loss:  0.9338266849517822\n",
            "epoch:  26  average loss:  0.9183529019355774\n",
            "epoch:  27  average loss:  0.8451845049858093\n",
            "epoch:  28  average loss:  0.7952651381492615\n",
            "epoch:  29  average loss:  0.7554804682731628\n",
            "epoch:  30  average loss:  0.711787223815918\n",
            "epoch:  31  average loss:  0.6778562664985657\n",
            "epoch:  32  average loss:  0.6354786157608032\n",
            "epoch:  33  average loss:  0.6007161140441895\n",
            "epoch:  34  average loss:  0.5657691359519958\n",
            "epoch:  35  average loss:  0.5485826730728149\n",
            "epoch:  36  average loss:  0.5253458619117737\n",
            "epoch:  37  average loss:  0.515051007270813\n",
            "epoch:  38  average loss:  0.5136749744415283\n",
            "epoch:  39  average loss:  0.5128320455551147\n",
            "epoch:  40  average loss:  0.49497488141059875\n",
            "epoch:  41  average loss:  0.4835759103298187\n",
            "epoch:  42  average loss:  0.4738788604736328\n",
            "epoch:  43  average loss:  0.45406636595726013\n",
            "epoch:  44  average loss:  0.44538235664367676\n",
            "epoch:  45  average loss:  0.4098651111125946\n",
            "epoch:  46  average loss:  0.3874572217464447\n",
            "epoch:  47  average loss:  0.3666912317276001\n",
            "epoch:  48  average loss:  0.34737882018089294\n",
            "epoch:  49  average loss:  0.33576667308807373\n",
            "Epochs = 50\n",
            "by the hair thas to go?\"\n",
            "\n",
            "\"Ohen at ut full bloff and I'll blow you to bof ow id\n",
            "frropngy, any suid the Wolf;\" s\n",
            "by the hair of my chin. Bry thosfid,\n",
            "\n",
            "The mechore?\"\n",
            "\n",
            "\n",
            "THE STORY OF THE THREE LITTLE PIGP\n",
            "Walnd; fed he\n",
            "huffad h\n",
            "by the hair oupl go; where mechind he puffed, and LI know wilock.\"\n",
            "\n",
            "\n",
            "Well, and I'll puff, and I'll puff, and I'\n",
            "by the hair\n",
            "housed; merze to?\" \n",
            "\"Othewner.\"\n",
            "\n",
            "Well, the house it ugher the little Pig; \"I THE TMnnd got the hous\n",
            "by the hair of\n",
            "mung mech ni.\"\n",
            "\n",
            "To; ang them pot shad you may you will at.\n",
            "\n",
            "OPi,\n",
            "and weis, and buch the apples, \n",
            "epoch:  0  average loss:  3.8930768966674805\n",
            "epoch:  1  average loss:  3.4209835529327393\n",
            "epoch:  2  average loss:  3.229332685470581\n",
            "epoch:  3  average loss:  3.1632072925567627\n",
            "epoch:  4  average loss:  3.0596160888671875\n",
            "epoch:  5  average loss:  2.9176371097564697\n",
            "epoch:  6  average loss:  2.731701135635376\n",
            "epoch:  7  average loss:  2.557814121246338\n",
            "epoch:  8  average loss:  2.409575939178467\n",
            "epoch:  9  average loss:  2.2769558429718018\n",
            "epoch:  10  average loss:  2.152930974960327\n",
            "epoch:  11  average loss:  2.032541036605835\n",
            "epoch:  12  average loss:  1.9152641296386719\n",
            "epoch:  13  average loss:  1.806587815284729\n",
            "epoch:  14  average loss:  1.7038055658340454\n",
            "epoch:  15  average loss:  1.6124745607376099\n",
            "epoch:  16  average loss:  1.5260753631591797\n",
            "epoch:  17  average loss:  1.4447861909866333\n",
            "epoch:  18  average loss:  1.3649126291275024\n",
            "epoch:  19  average loss:  1.2868331670761108\n",
            "epoch:  20  average loss:  1.211042046546936\n",
            "epoch:  21  average loss:  1.136173129081726\n",
            "epoch:  22  average loss:  1.0652872323989868\n",
            "epoch:  23  average loss:  1.006548285484314\n",
            "epoch:  24  average loss:  0.9607624411582947\n",
            "epoch:  25  average loss:  0.9371326565742493\n",
            "epoch:  26  average loss:  0.893703043460846\n",
            "epoch:  27  average loss:  0.8577279448509216\n",
            "epoch:  28  average loss:  0.8241971135139465\n",
            "epoch:  29  average loss:  0.7830834984779358\n",
            "epoch:  30  average loss:  0.7419941425323486\n",
            "epoch:  31  average loss:  0.7011405825614929\n",
            "epoch:  32  average loss:  0.6661298274993896\n",
            "epoch:  33  average loss:  0.6379375457763672\n",
            "epoch:  34  average loss:  0.601707398891449\n",
            "epoch:  35  average loss:  0.571904182434082\n",
            "epoch:  36  average loss:  0.5564847588539124\n",
            "epoch:  37  average loss:  0.5462602972984314\n",
            "epoch:  38  average loss:  0.5514470934867859\n",
            "epoch:  39  average loss:  0.5420979857444763\n",
            "epoch:  40  average loss:  0.5520294308662415\n",
            "epoch:  41  average loss:  0.5242267847061157\n",
            "epoch:  42  average loss:  0.5107035636901855\n",
            "epoch:  43  average loss:  0.491244912147522\n",
            "epoch:  44  average loss:  0.4581022560596466\n",
            "epoch:  45  average loss:  0.4416228234767914\n",
            "epoch:  46  average loss:  0.41602107882499695\n",
            "epoch:  47  average loss:  0.39589282870292664\n",
            "epoch:  48  average loss:  0.38514837622642517\n",
            "epoch:  49  average loss:  0.3736598491668701\n",
            "epoch:  50  average loss:  0.37317395210266113\n",
            "epoch:  51  average loss:  0.3600994050502777\n",
            "epoch:  52  average loss:  0.34887656569480896\n",
            "epoch:  53  average loss:  0.33340534567832947\n",
            "epoch:  54  average loss:  0.3224594295024872\n",
            "epoch:  55  average loss:  0.31476718187332153\n",
            "epoch:  56  average loss:  0.30296140909194946\n",
            "epoch:  57  average loss:  0.30816540122032166\n",
            "epoch:  58  average loss:  0.3153623342514038\n",
            "epoch:  59  average loss:  0.3048211634159088\n",
            "epoch:  60  average loss:  0.3130413889884949\n",
            "epoch:  61  average loss:  0.3037915527820587\n",
            "epoch:  62  average loss:  0.30738943815231323\n",
            "epoch:  63  average loss:  0.2858574092388153\n",
            "epoch:  64  average loss:  0.28065061569213867\n",
            "epoch:  65  average loss:  0.271708607673645\n",
            "epoch:  66  average loss:  0.25671708583831787\n",
            "epoch:  67  average loss:  0.25142261385917664\n",
            "epoch:  68  average loss:  0.2613350450992584\n",
            "epoch:  69  average loss:  0.24667823314666748\n",
            "epoch:  70  average loss:  0.2604384124279022\n",
            "epoch:  71  average loss:  0.26132288575172424\n",
            "epoch:  72  average loss:  0.27486857771873474\n",
            "epoch:  73  average loss:  0.29331174492836\n",
            "epoch:  74  average loss:  0.2995718717575073\n",
            "epoch:  75  average loss:  0.3943728506565094\n",
            "epoch:  76  average loss:  0.46985378861427307\n",
            "epoch:  77  average loss:  0.47117534279823303\n",
            "epoch:  78  average loss:  0.4772854745388031\n",
            "epoch:  79  average loss:  0.4752054214477539\n",
            "epoch:  80  average loss:  0.44360479712486267\n",
            "epoch:  81  average loss:  0.41284653544425964\n",
            "epoch:  82  average loss:  0.4031195640563965\n",
            "epoch:  83  average loss:  0.367544561624527\n",
            "epoch:  84  average loss:  0.3433152139186859\n",
            "epoch:  85  average loss:  0.3296835422515869\n",
            "epoch:  86  average loss:  0.2993328273296356\n",
            "epoch:  87  average loss:  0.2711655795574188\n",
            "epoch:  88  average loss:  0.2500040829181671\n",
            "epoch:  89  average loss:  0.22588308155536652\n",
            "epoch:  90  average loss:  0.20321691036224365\n",
            "epoch:  91  average loss:  0.18711252510547638\n",
            "epoch:  92  average loss:  0.1737436205148697\n",
            "epoch:  93  average loss:  0.16209053993225098\n",
            "epoch:  94  average loss:  0.15323364734649658\n",
            "epoch:  95  average loss:  0.14557980000972748\n",
            "epoch:  96  average loss:  0.13979299366474152\n",
            "epoch:  97  average loss:  0.1339971274137497\n",
            "epoch:  98  average loss:  0.1308208554983139\n",
            "epoch:  99  average loss:  0.12816369533538818\n",
            "Epochs = 100\n",
            "by the hair fll come for\n",
            " the little\n",
            "Pigs, and he huffed; bNom chinny came for\n",
            "dinner.\"\n",
            "\n",
            "\"Where?\" said the Wolf\n",
            "by the hair. So get bere the little Pig went off beforen, and got\n",
            "a nice pot-the llt all hom\n",
            "is house\"\n",
            "\n",
            "\"Yes, v\n",
            "by the hair of brig soked as said, \"Little Pig,\n",
            "what! is a that met all he said, \"Little Pig, let, with it upur\n",
            "by the hair of nick to-morrow, and he wis\n",
            "fryouge?\"\n",
            "\n",
            "\"Dhaing, I will come down from it he said, \"Little Pig, wa\n",
            "by the hair firtl blow ofort fim ve ready-Ar it to seek their\n",
            "fort him tureis a Man with a load of bricks, and \n"
          ]
        }
      ],
      "source": [
        "epochs = [5,25,50,100]\n",
        "outputs = []\n",
        "for j in range(4):\n",
        "\n",
        "    test_rnn = RNN(len(pigs_dev_vocab),20, 50)\n",
        "    hist = test_rnn.fit(x_pigs,y_pigs,epochs[j],1e-2,print_every_batch=50, print_every_epoch=1, filename = data_path+f'/pigs{j+3}_wts.npz')\n",
        "    print(f'Epochs = {epochs[j]}')\n",
        "    for i in range(5):\n",
        "        outputs.append(test_rnn.generate_sequence('by the hair', 100, char2ind_map_pigs, ind2char_map_pigs))\n",
        "        print(outputs[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w-U3CjKWm6q",
        "outputId": "fabf0d11-c8c4-4e10-c20f-71faa1e5b233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epochs = 5 \n",
            "\n",
            "by the hair Ne bongm,,ite\"\n",
            "i\n",
            "Yet c al:  hint\n",
            "hefw\n",
            "ire,o eei ,alsg wsetftrvt \"bua!tdt le nL   totle\"yPeWx an he \n",
            "by the hair\"eafau  bhiezdlirwsnid  Teenu  iostweT nit efE t e ewer Peanangaef sine dbW o ingu t gdea\"\n",
            "erc.  P P\n",
            "by the hair  t hnd IdeWnmt tcsiymceVcLeiag \" w\n",
            " i tnufWete ta\n",
            ",'rebVstyPupiH \"tIceno ero \"S e hSg wtaL\"e ieMplt\n",
            "by the hairatoWhPs ?\"bnee\n",
            "c At tp h oloet Wld  sesmdTesm\n",
            "itl e but.Egw Pset fadbdPtmlIennaon tedbgheshdaoP, tt \n",
            "by the hairT  t w thd.nVigetfrn p\"t a eoI ao I od.lano w\". agers\"g eS_el tn ugz,e\"Eftpleteso\"o\n",
            "SBen fuPlg\n",
            "el tf\n",
            "\n",
            "\n",
            "epochs = 25 \n",
            "\n",
            "by the hair at fir the little Piugk wot fece buid to thar time, he\n",
            "\n",
            "aadte -the Wothean wit to geth r:ow doussen\n",
            "by the hair in she an, whive;ry as at this said, \"Litt he suip to go Noe. So hy chin.\"\n",
            "\n",
            "\"Oh, wit the Whe soup.\"\n",
            "by the hair.\n",
            "THE LTTHE Souw youh he an\" said to the tot mun. san therxokn, And se puff\n",
            "ahy chinny at juft torn \n",
            "by the hair too\n",
            "heriryyyO, ases at oup, end bemow, and bet a Wolf.\n",
            "\n",
            "The to; walt fipl the Wolf came fusr a hur;\n",
            "by the hair time, ace buff and you bling, with of utle Pig me?lew.\"\n",
            "\n",
            "The t thin.\"\n",
            "\n",
            "TPigs,\" said, \"bild be blow \n",
            "\n",
            "\n",
            "epochs = 50 \n",
            "\n",
            "by the hair thas to go?\"\n",
            "\n",
            "\"Ohen at ut full bloff and I'll blow you to bof ow id\n",
            "frropngy, any suid the Wolf;\" s\n",
            "by the hair of my chin. Bry thosfid,\n",
            "\n",
            "The mechore?\"\n",
            "\n",
            "\n",
            "THE STORY OF THE THREE LITTLE PIGP\n",
            "Walnd; fed he\n",
            "huffad h\n",
            "by the hair oupl go; where mechind he puffed, and LI know wilock.\"\n",
            "\n",
            "\n",
            "Well, and I'll puff, and I'll puff, and I'\n",
            "by the hair\n",
            "housed; merze to?\" \n",
            "\"Othewner.\"\n",
            "\n",
            "Well, the house it ugher the little Pig; \"I THE TMnnd got the hous\n",
            "by the hair of\n",
            "mung mech ni.\"\n",
            "\n",
            "To; ang them pot shad you may you will at.\n",
            "\n",
            "OPi,\n",
            "and weis, and buch the apples, \n",
            "\n",
            "\n",
            "epochs = 100 \n",
            "\n",
            "by the hair fll come for\n",
            " the little\n",
            "Pigs, and he huffed; bNom chinny came for\n",
            "dinner.\"\n",
            "\n",
            "\"Where?\" said the Wolf\n",
            "by the hair. So get bere the little Pig went off beforen, and got\n",
            "a nice pot-the llt all hom\n",
            "is house\"\n",
            "\n",
            "\"Yes, v\n",
            "by the hair of brig soked as said, \"Little Pig,\n",
            "what! is a that met all he said, \"Little Pig, let, with it upur\n",
            "by the hair of nick to-morrow, and he wis\n",
            "fryouge?\"\n",
            "\n",
            "\"Dhaing, I will come down from it he said, \"Little Pig, wa\n",
            "by the hair firtl blow ofort fim ve ready-Ar it to seek their\n",
            "fort him tureis a Man with a load of bricks, and \n"
          ]
        }
      ],
      "source": [
        "for i in range(len(outputs)):\n",
        "  if i%5 ==0:\n",
        "    print(\"\\n\\nepochs =\",epochs[i//5],\"\\n\")\n",
        "  print(outputs[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edt2VytWMNpc"
      },
      "source": [
        "### 4c. Questions\n",
        "\n",
        "**Question 5:** Print out the 25 generated sequences, organized by the number of epochs the net that generated each sequence was trained for. Make several specific observations about the quality of text generated by each net as a function of the final loss.\n",
        "\n",
        "**Question 6:** Why is each network not generating the same 100 sequence every time you provide it with the same prompt?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCGb3oumMNpc"
      },
      "source": [
        "**Answer 5:** The net was more and more coherent as the sequences continued.  This directly corresponds to the final loss. For example, after 100 epochs we see text about the \"chinny chin chin\" which comes directly from the corpus.  And after 50 epochs the text generated is attempting to write the entire sotry again (likely triggered by the \\n character). 5 and 25 epochs make a lot of mistakes and are likely unconfident about which characters could go next, meaning that the random choice is especially problematic.\n",
        "\n",
        "**Answer 6:** We use the np.random.choice over our letters so we generate characters based on the activation they are assigned rather than the highest activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uJHcAykMNpc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLpe9QwVMNpd"
      },
      "source": [
        "## Task 4: Fairytale story teller\n",
        "\n",
        "Now that you are debugged your RNN and trained it on the story of the Three Little Pigs, you are ready to train a network on a much larger corpus! Train your RNN on a collection of children's fairytale stories (`fairytales_sm` corpus).\n",
        "\n",
        "### 4a. Load in the fairytale_sm corpus\n",
        "\n",
        "Adapt code from above to load in the `fairtale_sm` corpus.\n",
        "- The vocabulary should have `103` tokens.\n",
        "- There should be 80 mini-batches, 128 sequences/batch, and sequences have length 125 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXMntBDAMNpd",
        "outputId": "9d8db8a7-019f-4240-bd72-dd196f5c474b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fairytales set shape: (80, 128, 125)\n",
            "Fairytales labels shape: (80, 128, 125)\n",
            "Fairytales char2ind map loaded.\n",
            "Fairytales ind2char map loaded.\n"
          ]
        }
      ],
      "source": [
        "fairytales = np.load(data_path+'/fairytales_sm.npz')\n",
        "x_ft = fairytales['x']\n",
        "y_ft = fairytales['y']\n",
        "\n",
        "print(f'Fairytales set shape: {x_ft.shape}')\n",
        "print(f'Fairytales labels shape: {y_ft.shape}')\n",
        "\n",
        "with open(data_path+'/fairytales_sm_char2ind_map.pkl', 'rb') as file:\n",
        "    char2ind_map_ft = pickle.load(file)\n",
        "    print('Fairytales char2ind map loaded.')\n",
        "\n",
        "with open(data_path+'/fairytales_sm_ind2char_map.pkl', 'rb') as file:\n",
        "    ind2char_map_ft = pickle.load(file)\n",
        "    print('Fairytales ind2char map loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7urMPS3lMNpd"
      },
      "source": [
        "### 4b. Train your RNN on the fairytale_sm corpus\n",
        "\n",
        "**Tips:**\n",
        "1. Minimize print-outs to ensure your network training does not get bogged down, but it is helpful to have a progress printout with every loss after every epoch.\n",
        "2. This training session will take several hours on the GPU. Before running your \"real\" training session, I would suggest doing a short 1 epoch run and then generate text to make sure there are no unexpected crashes.\n",
        "3. How long you train for is up to you. Lower final losses will result in better/more coherent generated text. A rough target is avg loss of `0.7` (or better).\n",
        "4. Likewise, hyperparameters are also up to you. A recommended default is an embedding size of `32`, `1000` GRU neurons, and the default learning rate `1e-3` (*this is a lot bigger of a corpus than The Three Little Pigs!*).\n",
        "5. The questions in the next section revolve around text generated from your RNN. You may want to print out the RNN generated text in the cell below immediately after training the net because then you can look at the output even if Colab kills your runtime due to inactivity.\n",
        "6. Please let me know if you run into Colab's limits (e.g. you are unable to use the GPU runtime after some usage, Colab throttles your training to a crawl, etc.). I will try to set your team up with another solution.\n",
        "7. You are being provided with methods (`save_wts`, `load_wts` in `RNN`) to save your network weights to a file. Make sure your training code saves the weights after every epoch of training. If you do this and your training gets interrupts after several hours, create a new RNN with the same hyperparameters as before, but in the RNN constructor set `load_wts=True`. This will restore your network's weights to what they were right before your training got cut off!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "GKzqOe_xMNpd",
        "outputId": "61e72ca9-4298-48c6-ef08-fdb91bf91589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:  0  average loss:  0.6878598928451538\n",
            "epoch:  1  average loss:  0.6977488994598389\n",
            "epoch:  2  average loss:  0.6838098764419556\n",
            "epoch:  3  average loss:  0.671908974647522\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-6fe3118a6162>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mft_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar2ind_map_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mft_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_wts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/ft2_wts.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_every_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/ft3_wts.npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mseq_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Once upon a time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar2ind_map_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind2char_map_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mseq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A knight once sat at a large round table'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar2ind_map_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind2char_map_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gru_net.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, epochs, lr, verbose, print_every_epoch, print_every_batch, filename)\u001b[0m\n\u001b[1;32m    748\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" loss: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m             \u001b[0maverage_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gru_net.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, optimizer, loss, tape)\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mTODO\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTraverse\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31mâ†’\u001b[0m \u001b[0mbottom\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mback\u001b[0m \u001b[0mto\u001b[0m \u001b[0minput\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mrespective\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         '''\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gru_net.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, optimizer, loss, tape)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0md_wts\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0md_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_wts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SigmoidGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1238\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# y = sigmoid(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Keep me\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "# Your code here\n",
        "ft_rnn = RNN(len(char2ind_map_ft.keys()),32, 1000)\n",
        "ft_rnn.load_wts(data_path+'/ft2_wts.npz')\n",
        "hist = ft_rnn.fit(x_ft,y_ft,10,1e-3,print_every_batch=100, print_every_epoch=1, filename = data_path+\"/ft3_wts.npz\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "_5jgHeLZbHb6"
      },
      "outputs": [],
      "source": [
        "seq_1 = ft_rnn.generate_sequence('Once upon a time', 1200,char2ind_map_ft,ind2char_map_ft)\n",
        "seq2 = ft_rnn.generate_sequence('A knight once sat at a large round table', 1200,char2ind_map_ft,ind2char_map_ft)\n",
        "seq3 =ft_rnn.generate_sequence('In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort.', 5000,char2ind_map_ft,ind2char_map_ft)\n",
        "seq4 = ft_rnn.generate_sequence('Once upon a time', 100,char2ind_map_ft,ind2char_map_ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW0npm6dJS1R",
        "outputId": "863cf48c-cff6-4787-e63c-623115c7b045"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once upon a time arriving near\n",
            "to see her royaltiin, in scrrench with the beginning of\n",
            "animantal tobles that thus spring. It gops and summer's\n",
            "daughter, thought instagunny to go, it was let in twarmable and\n",
            "searching one magning the shades. Thus came out witt gift and dismay\n",
            "in the hote that the sea was consented. The work aroined on to a\n",
            "canny from the popital toker than he had fire on the\n",
            "sunshine, and ran on his hope he covered in three sudsing more\n",
            "belies that the Sea King Ransulan\n",
            "Whitt nothing. For a moment that nothing to be so; he had never even\n",
            "growing in letting his redarts for all the time, comprisend of his return.\n",
            "\n",
            "Book of forth wicked wish, and spilling it with before the Hen\n",
            "Poly Turesle to be glad so suce that it began\n",
            "that at the warRs racked hir on the house-to Leapnish.\n",
            "\n",
            "Before the wind must do so as the pours of swimming low in the\n",
            "most seczintong yellow waves around, burning this time to Unablesta tales.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "THE STORY OF THE ORAN  An Old Worthy Coppos. But he called a\n",
            "magiciny precious and monagine, buid he might marry one grandmother, a long jealous\n",
            "moment was sit and walks, and people in a pador,\n",
            "is it setmed any well-nightch.\n",
            "\n",
            " then one must must and bring meave esent to th\n",
            "A knight once sat at a large round table.\n",
            "\n",
            "The next day I should be a little cooking voice with two good cheerful as\n",
            "anybody. There caught a but to me, on a dream. I came to bed at least\n",
            "sa6.\n",
            "\n",
            "The counting Prince was the braves and queenly builting in the\n",
            "earlial at the Onstemnn And his fairily ray, as silenca\n",
            "he said all the harr. Never saw nothing about to remain in\n",
            "Palade and all the astender. The Knight became deviciol, he fell bedied\n",
            "that the preceping spirningly moment. The large and line gave the weets in a\n",
            "momonagus of is himself, and as he rode so soft.\n",
            "The skin of Mr. Faxise is here was a from this again.\n",
            "\n",
            "The innocence said Anay: \"Mack there save yourself, then, if you are\n",
            "dame!\"\n",
            "\n",
            "And Aladdin simage rellain like the Japa-for Fid THE Greed alord the\n",
            "glorious sword with horrid endilly to the one one, that count\n",
            "you this Mayer Baint from shall as passing. If anyone had before she loided in\n",
            "several times, thongs, he had accompleanly left the spirit, to weech it,\n",
            "and sent Bassor and pleasant song, for about for a mirror, that the\n",
            "proyest vencu. The real Joundation is now and arrow on the Japade\n",
            "of With as in the Urembenis stranger crads, on the place it\n",
            "was the lumus of the search of the Mrunthur_, and it was late\n",
            "\n",
            "In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort.\n",
            "\n",
            "She never tired the next morning, and it noing ball desacked\n",
            "invomptian.\n",
            "\n",
            "The wall, see his fairy back; and expice in a pity that he came to\n",
            "King Wantant. Fere as he had gove presents as a young Majentine, and\n",
            "he answered with FirtRRA; Hasen his sladd home, and as the monkey up\n",
            "valley, which been see how he forgot that time; gave hip a good fest.\n",
            "\n",
            "Now a moment was is to see how strong they grew to resent his forejoving gare\n",
            "collected in the need. The form lay quiet, the\n",
            "rain pupted him. While the wizard could not get the\n",
            "ogen leg like to save him for so long. No one hunged and down and they\n",
            "walched all the truckest prefious tame, that to his money with his\n",
            "captover and uglong to valce to him. This is a begone, because The\n",
            "great wed all the works from dancing. The dise's was\n",
            "soon gave an awan to dance to take a large cupbava, and the clubbs bemonds told\n",
            "him that this used with certain yours, for in hearrant greed\n",
            "time nor in a long many, for a shove land upon Faber Tales\n",
            "of his from one from demony and displaying their\n",
            "heads and diricingy years agoing the work of RoCherlack,\n",
            "and Dalapant-yaurh.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "THE OLD MANSTOR OF FLIVE CHOSPER\n",
            "\n",
            "\n",
            "Lond, lyngure Evenzedland, where was his years that he was a\n",
            "little word about it became very rock, and which made so\n",
            "much plwasuree you go to Japanese and The sea Kotain.\n",
            "\n",
            "\n",
            "The semprate told the pewsen of the shrewast shore, in complaint once in a pidate\n",
            "on the bones and the shore of the heavenly savere one to came and\n",
            "fetch the palace of the edge of the rosantâ€™s ned gamd to the\n",
            "ogre. Have my coverings before the words fram after pleasure\n",
            "and thinking of all the seffices of Dalsors was a long stick live mountain which it pain.\n",
            "\n",
            "The Empressâ€™s reparm down came on.\n",
            "\n",
            "The Dragon Kake whose father at the byen of his shollen ate so\n",
            "that quitt contained, perfarm, a white twelve general\n",
            "sprive inviten by himself. Aut this monny said any\n",
            "wonderful waves to the centipice of dunninâ€™s hand.\n",
            "\n",
            "The snow was sointed in Courtical, with the very object in this hole in\n",
            "hearch, and printed on the hope of feirned on his kind\n",
            "dismalsâ€™s househill snow. THis busin said returned. Who had\n",
            "got laid look in Dickess himself, but as lost it really help, in a\n",
            "few walls and gallant upon which the most strengthong belong\n",
            "the porrow.\n",
            "\n",
            "â€œIt is come, next doyâ€™s easing that you have dened the work of\n",
            "you, so that this is now brought him to count o cat to you.â€\n",
            "\n",
            "Then the time came for to call: till it returned.\n",
            "The poor chimper with was so tree, and they began to think of something\n",
            "grapsland.\n",
            "\n",
            "Urashimal grow onjeer. When his such richt hung up to the\n",
            "point, complying him when he had a knocking made of a poor windows,\n",
            "but at the spicitice was a bride. Beauty arred on a bad\n",
            "and myshly made into his form\n",
            "and sofe clear lump and promised. It could not\n",
            "suppose his breast broils on this money said:\n",
            "\n",
            "  I COmplyen's _Whod Rints\n",
            "o taill Mr. Am That's adfoming me. Mra. (_colven and This toury, which a\n",
            "compoment secks, ob popor I hid-here tear; and what it\n",
            "his break and two watch again,  o have me done ob. Im in the morn news a prime permissand with animy\n",
            "present my apponing bedrose, and immodint to my innocent hail in _Melequen sici, in\n",
            "_ceil. BEFB, receing to be grew us looking, and seven called Arabliabi, it\n",
            "againzzed.\n",
            "\n",
            "OF REMANPIR. B.OB. Well ribberings, saying, my famserstin\n",
            "including the song, forgetali. If any hish coldared sicks, wished the powred\n",
            "ese-tedrett not protect to be at the enough coldections from\n",
            "counting as a present to the Greatts Mountains _Faut_ No.\n",
            "20. Frenongh follows to remorn in this place,\n",
            "through 1.E.\" that Sontain pucts on the ogher\n",
            "pied on his kick minds of the same agree then like a beast. The infaivoss valuable saw such vissess.\n",
            "\n",
            "\n",
            "_Ver and _Folk-Lore of Rrcompl, Noh. Centra, afd only to _Tome three\n",
            "to go _Tougiten ey Buls_ of the nevers _Poubs. Thus be unshared (ix in\n",
            "teers in \"Gondingry. I have nobal anger--senzal covernion. Reve, eljore, On,\n",
            "id-it, you received in the turest it enough. I raised it to be a lard, and a\n",
            "Andicisus Ballad,\" pe lectraned and from a onlice in _Relly Whize Fairy, _.f._,\n",
            "ver-Jurisuies a difty pack, down, \"The soft shals are \"knestent\n",
            "the Marques and Eld.\"\n",
            "\n",
            "And the Mrinch seagl Mamotaro and Que neck it hulp of\n",
            "his quout stares, that a crack into the hills only.\"\n",
            "\n",
            "\"Never hands, but he has a large town, my lad, for he was come to for yourselvis again.\" When the roobsed viices\n",
            "with the girls of the bed were felt, and they filled with\n",
            "being cround it, and next snow, therefore to show gold and sile\n",
            "to their shoulders, for it had been throw and perhaps to\n",
            "eara ring, instead of being tender and carroas nothing whom they warm. Resignn that\n",
            "not one prevent a reality Four Caro was insudding; on a shower\n",
            "there are enough that it became three, puckived on tales around midding\n",
            "that was only round it thought. And all this treasurey to K\"NDurk][it was not a bush. I wished to remarn a\n",
            "jump or obour creature to be Longobar that told me\n",
            "on an only sound. Bettiently, my feet went to the \n",
            "Once upon a time, who same\n",
            "reproped to be hinged You the work on a severe of the Frejents for disturicing\n",
            "taxies Exi\n"
          ]
        }
      ],
      "source": [
        "print(seq_1)\n",
        "print(seq2)\n",
        "print(seq3)\n",
        "print(seq4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8C3Dd6qMNpd"
      },
      "source": [
        "### 4c. Generate fairytales using your trained RNN\n",
        "\n",
        "**Have fun** and try out several prompts! Among the ones you try, include `'Once upon a time'`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76yFjk6ZMNpd"
      },
      "source": [
        "### 4d. Questions\n",
        "**Question 7:** Do any groups of words/patterns recur across the generated text? What does this tell you about the themes/content in the corpus?\n",
        "\n",
        "**Question 8:** How is the grammar in the generated text? Why might this be the case?\n",
        "\n",
        "**Question 9:** How is the coherence of the generated story in the text? Why might this be the case?\n",
        "\n",
        "**Question 10:** What are some of your favorite generated passages / those that delighted you / those that made you laugh?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0a1AowGMNpd"
      },
      "source": [
        "**Answer 7:** The text likes to use all caps and 'name' a story after the \\n character.  Furthermore, it likes to make quotes everwhere occassionally forgetting to close them.\n",
        "\n",
        "**Answer 8:** The grammer is pretty good! It makes sentences, uses commas, makes paragraphs, captializes words.\n",
        "\n",
        "**Answer 9:**\n",
        "As the text progresses it becomes less and less coherent.  I expect this is because the context from the prompt is 'forgotten' as we get to a certain point in the text and it is only wokring with the likely error filled output that it has already made.  \n",
        "\n",
        "**Answer 10:**\n",
        "My favorite generated passage is from when I put in the first sentences of the Hobbit.  I got a cool bit of text after that with my favorite passage being: \"Now a moment was is to see how strong they grew to resent his forejoving gare\n",
        "collected in the need. The form lay quiet, the\n",
        "rain pupted him. While the wizard could not get the\n",
        "ogen leg like to save him for so long. No one hunged and down and they\n",
        "walched all the truckest prefious tame, that to his money with his\n",
        "captover and uglong to valce to him.\"  This is pretty incoherent but I liked that it came up with a wizard and a forboding body, which are part of the hobbit but not necessarily in the prompt that I gave. This mostly demonstrates that the themes of the corpus intersecting significantly to the Hobbit though."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ppJP8aMNpe"
      },
      "source": [
        "## Extensions\n",
        "\n",
        "### a. Reminder: AI Policy\n",
        "\n",
        "The goal of extensions is to learn and create something new beyond the base project that excites you. To serve this goal and out of fairness to your hardworking classmates, **AI (e.g. ChatGPT, Copilot, etc.) should NOT be used in ANY way on this project and extensions.** This includes both written analysis, plotting, and code. We will only grade **your** work, not an AI's. **We will stop grading your project if we notice AI-generated content (to any capacity).**\n",
        "\n",
        "### b. Guidelines\n",
        "\n",
        "To receive credit for any extension, you must:\n",
        "1. Not modify / prevent any code from the core project from working (e.g. make a copy before changing). In other words, **the notebook test code should still work!**\n",
        "2. **You must describe what you did and what you found in detail**. This includes a summary of parameter values used in your simulations.\n",
        "3. Include (*labeled!*) plots and/or numbers to present your results.\n",
        "4. Write up your extensions below or in a separate notebook.\n",
        "5. Give kudos to all sources, including anyone that you consulted.\n",
        "\n",
        "### c. Suggestions\n",
        "\n",
        "**Rule of thumb: one deep, thorough extension is worth more than several quick, shallow extensions!**\n",
        "\n",
        "The ideas below are **suggested** extensions â€” feel free to go in another direction related to this project that is not listed!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ8-8WBMMNpe"
      },
      "source": [
        "### 1. Weight initialization schemes\n",
        "\n",
        "We used He/Kaiming initialization because it supposedly speeds up training: getting the network to decrease loss faster than other methods. Compare the training loss curves for different weight initialization schemes. Is He/Kaiming the best?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcWgadqoMNpe"
      },
      "source": [
        "### 2. Hyperparameter search\n",
        "\n",
        "Focus on certain network hyperparameters (e.g. embedding size, number of GRU neurons) and either qualitatively or quantitatively analyze the impact on RNN performance (e.g. quality of generated text)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVqWzaQPMNpe"
      },
      "source": [
        "### 3. Preprocessing pipeline + your own corpus\n",
        "\n",
        "- Implement your own pipeline for creating the corpus vocabulary, token-to-int-code dictionaries, etc. Then train a RNN on a corpus of your choice.\n",
        "- Analyze the influence of sequence length and the quality of the RNN generated text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMyNDLYhMNpe"
      },
      "source": [
        "### 4. Stacked GRU layers\n",
        "\n",
        "We used a single GRU layer, but you can stack multiple GRU layers together to learn more complex/longer sequences. Adapt your network to support this and assess how it impacts generated text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zztGqbPAMNpe"
      },
      "source": [
        "### 5. Temperature in predictions\n",
        "\n",
        "In `generate_sequence` we predicted the next token in proportion of its softmax probability. You can introduce a \"temperature\" parameter that adjusts the softmax probability distribution to force the network to \"take more chances\" or \"be more conservative\" with the next char that it takes. For example, the temperature could raise the probability distribution by some power. Explore how the temperature affects the text that the network generates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lTS_-ifMNpe"
      },
      "source": [
        "### 6. Train on larger fairytale corpus\n",
        "\n",
        "There is also an even larger fairytale corpus `fairytale_lg` available to you. Train a RNN on the larger corpus and compare the generated text, final loss, speed of learning to the RNN you trained on `fairytale_sm`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlJ9bBddMNpe"
      },
      "source": [
        "### 7. Analyze/visualize probabilities of next char token\n",
        "\n",
        "- Modify `generate_sequence` to plot the softmax probability distribution for picking the next char. It is helpful to be thoughtful in how you label the plot (e.g. line the possible next chars on the x-axis, indicate in the title what the previous char was, indicate what char is actually selected as the next char from the distribution). Use the plots to help make sense of which chars are predicted from prompts of your choice.\n",
        "- Explore how the generated text changes if you swap out the probability-based method of selecting the next char with one that always selects the char with the highest probability."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
